\chapter{Appendix}
\section{Deriving Matrices for FEM Using Piecewise Linear Functions} \label{ap-mat-der}
The so called triangle function is defined as follows:
\begin{gather}
    \phi_j(x)= 
\begin{cases}
    (x - x_{j-1}) / \Delta x), \quad x_{j-1} \leq x <  x_{j}\\
    (x_{j+1} - x) / \Delta x), \quad x_{j} \leq x <  x_{j + 1}\\
    0,              \quad \text{otherwise}
\end{cases} \label{def-phi}
\end{gather}
\cite{Gustafsson2011d} \\
The following integrals have to be evaluated:
\begin{gather}
\int_{\chi} \phi_{j}\phi_{k}dx \quad \forall \phi_{k} \in \phi   \label{int-1} \\
-\int_{\chi} \frac{d\phi_{j}}{dx}\frac{d\phi_{k}}{dx}dx  \quad \forall \phi_{k} \in \phi  \label{int-2}
\end{gather}
With \(\chi \subset \mathbb{R}\). 
Note that the product of two functions \(\phi_j\) and \(\phi_k\) and their derivatives is only under two conditions not zero:

1. \(k = j\)

Considering this case the integral  \ref{int-1} becomes:
\begin{gather}
\int_{x_{j-1}}^{x_{j}} \phi_j^{2} dx + \int_{x_{j}}^{x_{j+1}} \phi_j^{2} dx 
\end{gather}
Because of symmetry only one of the above integrals have to computed:
\begin{gather}
2 \int_{x_{j-1}}^{x_{j}} \phi_j^{2} dx \\
= \frac{2}{\Delta x^2} \int_{x_{j-1}}^{x_{j}} (x-x_{j-1})^{2} dx \\
\frac{2}{3 \Delta x^{2}} \left[ (x - x_{j-1})^3\right]_{x_{j-1}}^{{x_j}} = \frac{2}{3 \Delta x^{2}} \Delta x^3 = \frac{2}{3}\Delta x
\end{gather}
Integral \ref{int-2} for \(i = j\) taking symmetry into account becomes:
\begin{gather}
-\int_{x_{j-1}}^{x_{j+1}} (\frac{d \phi_j}{dx})^2 dx = -\frac{1}{\Delta x^2} \int_{x_{j-1}}^{x_{j+1}} 1 dx\\
 = -\frac{1}{\Delta x^2}  \left[ x \right]_{x_{j-1}}^{x_{j+1}} = -\frac{2}{\Delta x}
\end{gather}

2. \(|j - k| = 1\)
\ref{int-1} becomes:
\begin{gather}
\frac{1}{\Delta x^2} \int_{x_j}^{x_{j+1}} (x-x_j)(x_{j+1} - x)dx \\
= \left[ \frac{1}{2} x^2 x_{j+1} - \frac{1}{3} x^3 - x x_{j+1} x_{j} + \frac{1}{2} x^2 x_j \right]_{x_j}^{x_{x_j+1}} 
= \frac{1}{6 \Delta x^2} \Delta x^3 = \frac{1}{6} \Delta x
\end{gather}
 
Finally \ref{int-2} has to be evaluated for this condition:
\begin{gather}
-\int_{x_j}^{x_{j+1}} \frac{d\phi_{j}}{dx}\frac{d\phi_{j+1}}{dx}dx = \frac{1}{\Delta x^2} \int_{x_j}^{x_{j+1}} 1 dx =  \frac{1}{\Delta x^2} \left[ x \right]_{x_{j}}^{x_{j+1}} = \frac{1}{\Delta x}
\end{gather}
\newpage
\section{Proof that Matrix M is Invertible}
\label{ap-K-inv}
Let \(M_{n}\) be a matrix with \(M_{n} \in \mathbb{R}^{n \times n}\) given by:
\begin{gather}
m_{ij} = \begin{cases}
a, \quad k = j \\
b, \quad |k - j| = 1 \\
0, \quad otherwise 
\end{cases}
\end{gather}
It's determinant is given by the Laplace expansion:
\begin{gather}
det(M_n) = \sum_{j=1}^{n} (-1)^{i+j} a_{ij} N_{ij} \quad \forall i
\end{gather}
\(N_{ij}\) is the determinant of the matrix \(M'\) that is obtained by removing the \(i^{th}\) row and \(j^{th}\) column of \(M_n\).
This expression can be simplified using the definition of \(m_{ij}\):
\begin{gather}
det(M_n) = a N_{11} - b N_{12} \label{1}
\end{gather}
\(N_{11}\) is equivalent to \(det(M_{n-1})\), since the indices of rows and columns of \(M'\) are in consecutive order and \(M'\) is a \(n-1 \times n-1\) matrix :
\begin{gather}
N_{11} = det(M') \\
M' = \begin{bmatrix}
m_{22} & \dots & m_{2n}\\
\vdots & \ddots & \vdots \\
m_{n2} & \dots & m_{nn}
\end{bmatrix}
\end{gather}
\(N_{12}\) can be obtained by calculating the determinant of \(M'\) using the Laplace expansion:
\begin{gather}
M' = \begin{bmatrix}
m_{21} & m_{23} & \dots & m_{2n}\\
\vdots & \vdots & \ddots & \vdots \\
m_{n1} & m_{n3} & \dots & m_{nn}
\end{bmatrix} \\
det(M') = m_{21} \cdot det(M'') \label{an1} \\
M'' = \begin{bmatrix}
m_{33} & \dots & m_{3n}\\
\vdots & \ddots & \vdots \\
m_{n3} & \dots & m_{nn}
\end{bmatrix}
\end{gather}

In \ref{an1} only the stated term has to be evaluated since all entries of the first column of the second sub matrix are zero. 
Therefore the determinant is zero.
The row and column indices of \(M''\) are in consecutive order and it is a \(n-2 \times n-2\) matrix.
Therefore \(M''\) is equivalent to \(M_{n-2}\).
\ref{1} becomes:
\begin{gather}
det(M_n) = a \cdot det(M_{n-1}) - b^{2} \cdot det(M_{n-2})
\end{gather}
Furthermore this implies \(det(M_0) = 1\):
\begin{gather}
det(M_2) = a^{2} - b^{2} =  a \cdot det(M_1) - b^{2} \cdot 1 \\
\Rightarrow det(M_0) = 1
\end{gather}
Using the definition of \ref{def-mat-a} and \ref{def-delta-x} this can be seen as the following sequence:
\begin{gather}
a_0 = 1, \; a_1 = \frac{2 \Delta x}{3} \\
a_{n+1} = \frac{2 \Delta x}{3} \cdot a_{n} - \frac{\Delta x^2}{36} \cdot a_{n-1} 
\end{gather}
As described here \cite{Michael2017} a recursive sequence converges if it is monotone and has a limit.
A proof by induction shows that this sequence is monotone for \(n \geq 1\).


Base case:
\begin{gather}
a_{2} = (\frac{2 \Delta x}{3})^{2} - \frac{\Delta x^{2}}{36} = \Delta x^{2} (\frac{4}{9} - \frac{1}{36}) < \frac{2 \Delta x}{3} = a_{1}
\end{gather}
Induction step: Assuming that \(a_k < a_{k-1}\) holds, \(a_{k+1} < a_{k}\) also holds:
\begin{gather}
a_{k+1} = \frac{2 \Delta x}{3} \cdot a_{k} - \frac{\Delta x^2}{36} \cdot a_{k-1}  < \frac{2 \Delta x}{3} \cdot a_{k-1} - \frac{\Delta x^2}{36} \cdot a_{k-2} = a_{k} 
\end{gather}
The limit of this sequence is as follow:
\begin{gather}
\alpha = \lim_{n \to \infty} a_{n+1} = \lim_{n \to \infty} \Delta x \cdot \frac{2}{3} \cdot \lim_{n \to \infty} a_{n} - \lim_{n \to \infty} \Delta x^{2} 
\cdot \frac{1}{36} \cdot \lim_{n \to \infty} a_{n-1} 
= 0 \cdot \alpha - 0 \cdot \alpha = 0
\end{gather}
Since this series is monotone and converges to zero as \(n\) goes to infinity, there is no \(n \in \mathbb{N}\) for which \(a_n = 0\). 
Therefore the determinant of the matrix \(M\) defined in \ref{def-mat-a} is not zero and \(M\) is invertible.
\section{Equivalence of Piecewise Linear Polynomials and Linear Interpolation} \label{ap-lin-interp}
A piecewise linear polynomial in the form of:
\begin{gather}
u(x, t) = \sum_{j = 1}^{N} c_{j}(t)\phi_{j}(x)
\end{gather}
With \(\phi_{j}\) being defined as \ref{def-phi} and \(c_{j}: \mathbb{R} \rightarrow \mathbb{R} \) is equivalent to linear interpolation with respect to \(x\):
\begin{gather}
\hat{u}(x,t) =  u_{j} + \frac{(u_{j+1} - u_{j})(x-x_{j})}{x_{j+1} - x_{j}} 
\end{gather}
for \(x_{j} < x < x_{j+1}\) \cite{Bayen2015}. 
This can be shown by evaluating \(u(x, t)\) between two neigbouring \(\phi\) and \(x_{j} < x < x_{j+1}\):
\begin{gather}
u(x, t) = \phi_{j}(x) c_{j}(t) + \phi_{j+1}(x) c_{j+1}(t) \\
= \frac{x_{j+1} - x}{\Delta x} c_{j}(t) + \frac{x - x_{j}}{\Delta x} c_{j+1}(t) \\
= \frac{x_{j+1} - x}{\Delta x} u_{j} + \frac{x - x_{j}}{\Delta x} u_{j+1} \\
= \frac{(x_{j+1}u_{j} - xu_{j}) + (x u_{j+1}  - x_{j} u_{j+1})}{\Delta x} \\
= \frac{(u_{j+1} - u_{j})x + x_{j+1}u_{j} - x_{j} u_{j+1}}{\Delta x} \\
= \frac{(u_{j+1} - u_{j})x + x_{j}u_{j} + \Delta x u_{j} - x_{j} u_{j+1}}{\Delta x} \\
= u_{j} + \frac{(u_{j+1} - u_{j})x - x_{j}(u_{j+1} - u_{j})}{\Delta x} \\
= u_{j} + \frac{(u_{j+1} - u_{j})(x - x_{j})}{x_{j+1} - x_{j}}
\end{gather}

\pagebreak
\section{Source Code}
The source code described in chapter \ref{chap-impl} is available on github:

\href{https://github.com/FlorianGelb/FEM/tree/abgabe}{https://github.com/FlorianGelb/FEM/tree/abgabe}.
It can be downloaded using the following commands:
\begin{itemize}
 \item git clone [URL]
 \item git checkout abgabe
\end{itemize}
Here for example test.m can be executed to generate some figures similar to figure \ref{FIG-POD}.
The exact commit is 306d9ee27fbf2c8288b6ecd11cbd7bb22a7cc9ce.
To make sure this exact version is used, use the git reset command.


